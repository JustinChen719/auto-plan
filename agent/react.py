from abc import abstractmethod, ABC

from core.llm import LLM, LLMName, LLMResponseContent
from tools import get_tool_mapper, FinishTool
from agent.base import BaseAgent
from utils import get_logger

logger = get_logger(__name__)


class ReActAgent(BaseAgent, ABC):
    """
    Reasoning Action Agent
    """

    def __init__(self):
        super().__init__()

        # å·¥å…·è°ƒç”¨agent å…è®¸è°ƒç”¨çš„tool
        self.allowed_tool_call_names: list[str] = []
        # ç»“æœ
        self.result: None | str = None

        self.llm = LLM(LLMName.QWEN3_32B)

    def reset(self) -> None:
        self.current_query = None
        self.current_step = 0
        self.memory.clear()
        self.finished = False
        self.failed = False
        self.result = None
        if self.system_prompt:
            self.memory.add_system_message(self.system_prompt)

    async def think(self) -> LLMResponseContent:
        logger.info(f"ğŸ§  {self.name} Stepã€{self.current_step}/{self.max_step}ã€‘ æ­£åœ¨æ€è€ƒä¸­...")
        self.memory.add_user_message(content=self.current_prompt)

        # è®¾ç½® tools
        tool_mapper = get_tool_mapper()
        tools = [tool_mapper[tool_name].get_tool_call_params() for tool_name in self.allowed_tool_call_names]

        # è·å–å›å¤å†…å®¹
        response: LLMResponseContent = await self.llm.response(
                memory=self.memory,
                tools=tools
        )
        self.memory.add_assistant_message(content=response.content, tool_calls=response.tool_calls)
        return response

    async def act(
            self,
            tool_call_id: str,
            tool_call_name: str,
            tool_call_params: dict
    ) -> None | str:
        """
        å·¥å…·è°ƒç”¨
        """

        if tool_call_name not in self.allowed_tool_call_names:
            raise ValueError(f"æ™ºèƒ½ä½“ {self.name} æ²¡æœ‰ {tool_call_name} è¿™ä¸ªå·¥å…·ï¼")

        tool_mapper = get_tool_mapper()
        if tool_call_name in tool_mapper:
            tool = tool_mapper[tool_call_name]

            # æ£€æŸ¥å‚æ•°
            if tool.check_params(tool_call_params):
                logger.info(f"âš™ï¸ {tool_call_name} å·¥å…·è¢«è°ƒç”¨ï¼")
                tool_response = await tool.execute(tool_call_params)

                if tool_response is None:
                    logger.info(f"ğŸ”´ {tool_call_name} å·¥å…·æ‰§è¡Œå¤±è´¥ï¼")
                    self.failed = True
                    return None

                # æ˜¯å¦è°ƒç”¨äº†ç»“æŸå·¥å…·
                if tool_call_name == FinishTool.name:
                    self.finished = True
                    self.result = tool_response

                self.memory.add_tool_message(
                        content=tool_response,
                        tool_call_id=tool_call_id
                )
                return tool_response
            else:
                raise ValueError(f"è°ƒç”¨ {tool_call_name} æ—¶æä¾›çš„å‚æ•° {tool_call_params} æœ‰é—®é¢˜ï¼")
        else:
            raise ValueError(f"æ²¡æœ‰ {tool_call_name} è¿™ä¸ªå·¥å…·ï¼")

    async def step(self) -> LLMResponseContent:
        # æ€è€ƒ
        response: LLMResponseContent = await self.think()

        # æ‰§è¡Œå·¥å…·
        for tool_call in response.tool_calls:
            await self.act(
                    tool_call_id=tool_call.id,
                    tool_call_name=tool_call.name,
                    tool_call_params=tool_call.arguments
            )
        return response
