from agent.base import BaseAgent
from core.llm import LLMName, LLM, LLMResponseContent
from utils import get_logger

logger = get_logger(__name__)


class SummaryAgent(BaseAgent):
    name: str = "SummaryAgent"
    description: str = "æ€»ç»“è€…ï¼Œæ ¹æ®ç›®æ ‡å’Œå½“å‰æ‰§è¡ŒçŠ¶æ€ã€æ‰§è¡Œç»“æœï¼Œç»™å‡ºæ€»ç»“ä½œä¸ºæœ€ç»ˆäº¤ç»™ç”¨æˆ·çš„ç­”å¤ã€‚"

    def __init__(self):
        super().__init__()
        self.current_results: list[str] = []

        self.memory.add_system_message(self.system_prompt)
        self.llm = LLM(LLMName.QWEN3_32B)

    def reset(self) -> None:
        self.current_query = None
        self.current_results = []
        # self.current_step = 0
        self.memory.clear()
        self.finished = False
        self.failed = False
        if self.system_prompt:
            self.memory.add_system_message(self.system_prompt)

    async def think(self) -> LLMResponseContent:
        # è®¾ç½® prompt
        prompt: str = self.next_step_prompt.format(
                query=self.current_query,
                results="\n".join(self.current_results))
        self.memory.add_user_message(content=prompt)

        # è·å–å›å¤å†…å®¹
        response: LLMResponseContent = await self.llm.response(
                memory=self.memory,
                display_reasoning_content=False,
                display_content=False,
        )
        self.memory.add_assistant_message(content=response.content)
        return response

    async def step(self) -> LLMResponseContent:
        response = await self.think()
        return response

    async def run(self, query: str, results: list[str]) -> LLMResponseContent:
        logger.info(f"âœ¨ï¸ {self.name} æ­£åœ¨æ€»ç»“ç»“æœ...")

        self.current_query = query
        self.current_results = results

        # åªæ‰§è¡Œä¸€æ­¥
        response: LLMResponseContent = await self.step()
        logger.info(f"ğŸ“ {self.name} æ€»ç»“ç»“æœï¼š\n{response}")
        return response
